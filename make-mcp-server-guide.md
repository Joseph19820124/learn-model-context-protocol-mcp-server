# 什么是MCP服务器？模型上下文协议助力AI代理

今天，我们将介绍一种让你的AI更加强大的方法：Make模型上下文协议(MCP)服务器。这个基于云的网关通过标准化协议将你的AI代理连接到Make场景中——无需管理API端点、安装本地代码或维护基础设施。让我们来看看这意味着什么，以及如何开始使用它。

## 解决API标准化问题

想象一下，如果没有与网络交互的标准化协议会是什么样子。每次访问网站时，你都必须选择合适的浏览器才能正确查看页面。听起来很令人沮丧，对吧？这正是当前API状态的真实写照：它们在处理身份验证、数据序列化和反序列化，甚至错误报告方面存在无数变化。

在Make，我们在过去十年中为数千个API构建了通用连接器，这样你就不必自己做了。这些连接器旨在简化和简化API之间的通信，确保无缝检索和使用数据。

## MCP的作用

这就是MCP发挥作用的地方。MCP——模型上下文协议——标准化了AI如何发现API端点，帮助它们理解每个端点执行的操作，并清楚地定义预期的输入和输出。这为你的Make AI代理提供了精确的指导，并通过限制任何给定任务中涉及的变量来减少幻觉的可能性。

简单地说，它为你的AI提供工具，并概述它们如何工作，以增加正确使用它们的可能性。这是AI自动化演进的下一步。

但在Make，我们相信MCP不仅有潜力成为连接工具和服务与AI以实现代理目的的通用协议，而且还可能成为确定性工作流自动化平台的基础层。它可以显著减少从头重建连接器所花费的时间和精力，让我们能够更快地提供更多连接器。

## 如何使用Make MCP服务器

### 第一步：在Make中创建场景

在Make中创建一个或多个场景。这些场景可以简单也可以复杂，可以使用AI也可以不使用AI。每个场景都应该配置场景输出来构建你的AI将接收的数据；在必要时，你还可以为场景配置场景输入。

### 第二步：让MCP服务器可以访问你的场景

你希望通过MCP使用的每个场景都必须设置为活动状态和按需状态。

### 第三步：获取你的MCP令牌

1. 导航到Make用户配置文件中的API/MCP访问部分
2. 点击"添加令牌"并选择"MCP令牌"作为类型
3. 为你的MCP令牌选择一个标签并点击"添加"
4. 复制此URL

### 第四步：配置AI模型

1. 转到AI模型的配置区域
2. 粘贴你的令牌URL

现在你的AI可以找到你的可用场景，像工具一样运行它们，并获得真实结果——无需任何代码或额外设置。

## MCP的价值

MCP为你的AI代理提供了一个工具箱。它通过以下方式改变了工具集成：

- **标准化集成**：不再需要为每个数据源维护单独的连接器，开发者现在可以针对标准协议进行构建
- **上下文保持**：随着生态系统的成熟，AI系统将在不同工具和数据集之间移动时保持上下文
- **可持续架构**：用更可持续的架构替代今天碎片化的集成

开发者现在就可以开始构建和测试MCP连接器。所有Claude.ai计划都支持将MCP服务器连接到Claude桌面应用程序。Claude for Work客户可以开始在本地测试MCP服务器，将Claude连接到内部系统和数据集。

## 技术架构

MCP采用客户端-服务器架构，包含三个主要组件：

### MCP客户端
集成在主机应用程序内，处理与MCP服务器的连接，在主机要求和模型上下文协议之间进行转换。

### MCP服务器
添加上下文和功能，通过MCP向AI应用程序公开特定功能。每个独立服务器通常专注于特定的集成点，如用于仓库访问的GitHub或用于数据库操作的PostgreSQL。

### 传输层
客户端和服务器之间的通信机制。MCP支持两种主要传输方法：
- **STDIO**（标准输入/输出）：主要用于服务器在与客户端相同环境中运行的本地集成
- **HTTP+SSE**（服务器发送事件）：远程连接，使用HTTP进行客户端请求，SSE用于服务器响应和流传输

## 安全考虑

安全责任主要落在服务器开发者身上，他们应该严格遵循最小权限原则。理想情况下，MCP服务器只会请求其功能所需的最低访问权限。这确保服务器不会意外暴露给敏感数据，同时增强对利用不同资源之间不安全连接的供应链攻击的弹性。

## 总结

模型上下文协议代表了连接LLM到外部系统的重大飞跃，标准化了一个碎片化的生态系统，并可能解决N×M问题。通过统一AI应用程序与工具和数据源的对话方式，MCP减少了开发开销，实现了一个更具互操作性的生态系统，其中创新惠及整个社区——而不是保持孤立状态。

如果你想了解更多详细信息，请访问我们开发者中心的MCP服务器页面。

---

*本文档翻译自Make.com关于模型上下文协议(MCP)服务器的官方博客文章。*